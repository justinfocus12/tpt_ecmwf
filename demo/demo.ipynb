{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import netCDF4 as nc\n",
    "import model_crommelin_seasonal\n",
    "import feature_crommelin \n",
    "from importlib import reload\n",
    "import sys \n",
    "import os\n",
    "from os import mkdir\n",
    "from os.path import join,exists\n",
    "from importlib import reload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create directories to save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_dir = \"/scratch/jf4241/crommelin\"\n",
    "if not exists(topic_dir): mkdir(topic_dir)\n",
    "day_dir = join(topic_dir,\"2022-07-22\")\n",
    "if not exists(day_dir): mkdir(day_dir)\n",
    "exp_dir = join(day_dir,\"1\")\n",
    "if not exists(exp_dir): mkdir(exp_dir)\n",
    "ra_dir = join(exp_dir,\"reanalysis_data\")\n",
    "if not exists(ra_dir): mkdir(ra_dir)\n",
    "ra_dir_contiguous = join(ra_dir,\"contiguous\") # For long, unbroken record\n",
    "if not exists(ra_dir_contiguous): mkdir(ra_dir_contiguous)\n",
    "ra_dir_seasonal = join(ra_dir,\"seasonal\") # For data split into seasons\n",
    "if not exists(ra_dir_seasonal): mkdir(ra_dir_seasonal)\n",
    "hc_dir = join(exp_dir,\"hindcast_data\")\n",
    "if not exists(hc_dir): mkdir(hc_dir)\n",
    "featspec_dir = join(exp_dir,\"featspec\") # Metadata with info to compute features\n",
    "if not exists(featspec_dir): mkdir(featspec_dir)\n",
    "results_dir = join(exp_dir,\"results\")\n",
    "if not exists(results_dir): mkdir(results_dir)\n",
    "results_dir_ra = join(results_dir,\"ra\")\n",
    "if not exists(results_dir_ra): mkdir(results_dir_ra)\n",
    "results_dir_hc = join(results_dir,\"hc\")\n",
    "if not exists(results_dir_hc): mkdir(results_dir_hc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set physical parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_samp = 0.5 # Time step to save out\n",
    "dt_szn = 0.74 # Time resolution for the seasonal model \n",
    "szn_start = 300.0\n",
    "szn_length = 250.0\n",
    "year_length = 400.0\n",
    "Nt_szn = int(szn_length / dt_szn)\n",
    "szn_avg_window = 5.0\n",
    "burnin_time = 500.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'model_crommelin_seasonal' from '/home/jf4241/ecmwf/tpt_ecmwf/demo/model_crommelin_seasonal.py'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(model_crommelin_seasonal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fundamental_param_dict = dict({\"b\": 0.5, \"beta\": 1.25, \"gamma_limits\": [0.15, 0.22], \"C\": 0.1, \"x1star\": 0.95, \"r\": -0.801, \"year_length\": year_length})\n",
    "crom = model_crommelin_seasonal.SeasonalCrommelinModel(fundamental_param_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create \"reanalysis\" in the file folder reserved for contiguous data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_filename_ra = join(ra_dir_contiguous,\"crom_long.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integrated through time 1000.0000000001588 out of 2499.5\n",
      "Integrated through time 2000.0999999992764 out of 2499.5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "multi-dimensional array attributes not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m tmax_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\u001b[38;5;241m*\u001b[39mfundamental_param_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myear_length\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m burnin_time\n\u001b[1;32m      6\u001b[0m t_save \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m,tmax_save,dt_samp)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mcrom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintegrate_and_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43mt_save\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtraj_filename_ra\u001b[49m\u001b[43m,\u001b[49m\u001b[43mburnin_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mburnin_time\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ecmwf/tpt_ecmwf/demo/model_crommelin_seasonal.py:295\u001b[0m, in \u001b[0;36mSeasonalCrommelinModel.integrate_and_save\u001b[0;34m(self, x0, t_save, traj_filename, burnin_time)\u001b[0m\n\u001b[1;32m    293\u001b[0m     keys2save\u001b[38;5;241m.\u001b[39mremove(key)\n\u001b[1;32m    294\u001b[0m ds\u001b[38;5;241m.\u001b[39mattrs \u001b[38;5;241m=\u001b[39m {key: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq[key] \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m keys2save}\n\u001b[0;32m--> 295\u001b[0m \u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_netcdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraj_filename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.9/site-packages/xarray/core/dataset.py:1900\u001b[0m, in \u001b[0;36mDataset.to_netcdf\u001b[0;34m(self, path, mode, format, group, engine, encoding, unlimited_dims, compute, invalid_netcdf)\u001b[0m\n\u001b[1;32m   1897\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1898\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_netcdf\n\u001b[0;32m-> 1900\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mto_netcdf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1901\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1902\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1903\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1904\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1905\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1906\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1907\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1908\u001b[0m \u001b[43m    \u001b[49m\u001b[43munlimited_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munlimited_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1909\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1910\u001b[0m \u001b[43m    \u001b[49m\u001b[43minvalid_netcdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minvalid_netcdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1911\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.9/site-packages/xarray/backends/api.py:1072\u001b[0m, in \u001b[0;36mto_netcdf\u001b[0;34m(dataset, path_or_file, mode, format, group, engine, encoding, unlimited_dims, compute, multifile, invalid_netcdf)\u001b[0m\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;66;03m# TODO: figure out how to refactor this logic (here and in save_mfdataset)\u001b[39;00m\n\u001b[1;32m   1068\u001b[0m \u001b[38;5;66;03m# to avoid this mess of conditionals\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1070\u001b[0m     \u001b[38;5;66;03m# TODO: allow this work (setting up the file for writing array data)\u001b[39;00m\n\u001b[1;32m   1071\u001b[0m     \u001b[38;5;66;03m# to be parallelized with dask\u001b[39;00m\n\u001b[0;32m-> 1072\u001b[0m     \u001b[43mdump_to_store\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1073\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munlimited_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munlimited_dims\u001b[49m\n\u001b[1;32m   1074\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1075\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m autoclose:\n\u001b[1;32m   1076\u001b[0m         store\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.9/site-packages/xarray/backends/api.py:1119\u001b[0m, in \u001b[0;36mdump_to_store\u001b[0;34m(dataset, store, writer, encoder, encoding, unlimited_dims)\u001b[0m\n\u001b[1;32m   1116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoder:\n\u001b[1;32m   1117\u001b[0m     variables, attrs \u001b[38;5;241m=\u001b[39m encoder(variables, attrs)\n\u001b[0;32m-> 1119\u001b[0m \u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_encoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munlimited_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munlimited_dims\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.9/site-packages/xarray/backends/common.py:263\u001b[0m, in \u001b[0;36mAbstractWritableDataStore.store\u001b[0;34m(self, variables, attributes, check_encoding_set, writer, unlimited_dims)\u001b[0m\n\u001b[1;32m    259\u001b[0m     writer \u001b[38;5;241m=\u001b[39m ArrayWriter()\n\u001b[1;32m    261\u001b[0m variables, attributes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode(variables, attributes)\n\u001b[0;32m--> 263\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_attributes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattributes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_dimensions(variables, unlimited_dims\u001b[38;5;241m=\u001b[39munlimited_dims)\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_variables(\n\u001b[1;32m    266\u001b[0m     variables, check_encoding_set, writer, unlimited_dims\u001b[38;5;241m=\u001b[39munlimited_dims\n\u001b[1;32m    267\u001b[0m )\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.9/site-packages/xarray/backends/common.py:280\u001b[0m, in \u001b[0;36mAbstractWritableDataStore.set_attributes\u001b[0;34m(self, attributes)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;124;03mThis provides a centralized method to set the dataset attributes on the\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;124;03mdata store.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03m    Dictionary of key/value (attribute name / attribute) pairs\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m attributes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 280\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_attribute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.9/site-packages/xarray/backends/netCDF4_.py:451\u001b[0m, in \u001b[0;36mNetCDF4DataStore.set_attribute\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds\u001b[38;5;241m.\u001b[39msetncattr_string(key, value)\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetncattr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2824\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Dataset.setncattr\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:1583\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4._set_att\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: multi-dimensional array attributes not supported"
     ]
    }
   ],
   "source": [
    "# Run the model forward\n",
    "x0 = np.zeros((1,7))\n",
    "x0[0,6] = (1957 + 0.2)*fundamental_param_dict[\"year_length\"]  # Starting time is about 20% of the way through 1957 (arbitrary)\n",
    "dt_save = 0.5\n",
    "tmax_save = 5*fundamental_param_dict[\"year_length\"] + burnin_time\n",
    "t_save = np.arange(0,tmax_save,dt_samp)\n",
    "crom.integrate_and_save(x0,t_save,traj_filename_ra,burnin_time=burnin_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(traj_filename_ra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'b': 0.5,\n",
       " 'beta': 1.25,\n",
       " 'gamma_limits': array([0.15, 0.22]),\n",
       " 'C': 0.1,\n",
       " 'x1star': 0.95,\n",
       " 'r': -0.801,\n",
       " 'year_length': 400.0,\n",
       " 'xstar': array([ 0.95   ,  0.     ,  0.     , -0.76095,  0.     ,  0.     ]),\n",
       " 'alpha': array([0.24008435, 0.73437566]),\n",
       " 'delta': array([ 0.38413496, -1.24278958]),\n",
       " 'epsilon': 1.44050610585137}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_filename_ra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create \"hindcast\" data in the file folder reserved for hindcast data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate hindcast dataset\n",
    "t_abs_range = crom.q[\"year_length\"]*np.array([1960,1970])\n",
    "crom.generate_hindcast_dataset(\n",
    "    traj_filename_ra,hc_dir,t_abs_range,dt_samp,\n",
    "    ens_size=30,ens_duration=47,ens_gap=13,pert_scale=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract features of interest from both the reanalysis and hindcast datasets. This will be expensive, as we have to read from a large database of files. Therefore, we should minimize the number of times we do this in development. Therefore, we should read in ALL possible features we MIGHT use for the downstream tasks of K-means clustering. Some extra reduction is likely necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all features of potential use from the reanalysis dataset. \n",
    "# Don't waste data by time-delaying, that's just silly\n",
    "feat_crom = feature_crommelin.SeasonalCrommelinModelFeatures(\n",
    "    szn_start,szn_length,year_length,Nt_szn,\n",
    "    szn_avg_window,dt_samp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the already-executed model (contiguous)\n",
    "X_ra_cont = xr.open_dataset(traj_filename_ra)[\"X\"]\n",
    "print(X_ra_cont.sel(feature=\"x1\").isel(t_sim=0))\n",
    "print(X_ra_cont.sel(feature=\"x2\").isel(t_sim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot x1 and x4 over time for 4 annual cycles\n",
    "fig,ax = plt.subplots(ncols=2, figsize=(12,6))\n",
    "xr.plot.plot(\n",
    "    X_ra_cont.sel(feature='x1',member=0)\n",
    "    .where(X_ra_cont['t_sim'] < 4*crom.q[\"year_length\"], drop=True),\n",
    "    x='t_sim', ax=ax[0]\n",
    ")\n",
    "xr.plot.plot(\n",
    "    X_ra_cont.sel(feature='x4',member=0)\n",
    "    .where(X_ra_cont['t_sim'] < 4*crom.q[\"year_length\"], drop=True),\n",
    "    x='t_sim', ax=ax[1]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the climatology\n",
    "feat_crom.compute_climatology(in_filename,save_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some hindcasts on top of climatology\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
