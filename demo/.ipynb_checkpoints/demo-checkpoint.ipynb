{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import netCDF4 as nc\n",
    "import model_crommelin_seasonal\n",
    "import feature_crommelin \n",
    "from importlib import reload\n",
    "import sys \n",
    "import os\n",
    "from os import mkdir\n",
    "from os.path import join,exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create directories to save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_dir = \"/scratch/jf4241/crommelin\"\n",
    "if not exists(topic_dir): mkdir(topic_dir)\n",
    "day_dir = join(topic_dir,\"2022-07-22\")\n",
    "if not exists(day_dir): mkdir(day_dir)\n",
    "exp_dir = join(day_dir,\"1\")\n",
    "if not exists(exp_dir): mkdir(exp_dir)\n",
    "ra_dir = join(exp_dir,\"reanalysis_data\")\n",
    "if not exists(ra_dir): mkdir(ra_dir)\n",
    "ra_dir_contiguous = join(ra_dir,\"contiguous\") # For long, unbroken record\n",
    "if not exists(ra_dir_contiguous): mkdir(ra_dir_contiguous)\n",
    "ra_dir_seasonal = join(ra_dir,\"seasonal\") # For data split into seasons\n",
    "if not exists(ra_dir_seasonal): mkdir(ra_dir_seasonal)\n",
    "hc_dir = join(exp_dir,\"hindcast_data\")\n",
    "if not exists(hc_dir): mkdir(hc_dir)\n",
    "featspec_dir = join(exp_dir,\"featspec\") # Metadata with info to compute features\n",
    "if not exists(featspec_dir): mkdir(featspec_dir)\n",
    "results_dir = join(exp_dir,\"results\")\n",
    "if not exists(results_dir): mkdir(results_dir)\n",
    "results_dir_ra = join(results_dir,\"ra\")\n",
    "if not exists(results_dir_ra): mkdir(results_dir_ra)\n",
    "results_dir_hc = join(results_dir,\"hc\")\n",
    "if not exists(results_dir_hc): mkdir(results_dir_hc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set physical parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_samp = 0.5 # Time step to save out\n",
    "dt_szn = 0.74 # Time resolution for the seasonal model \n",
    "szn_start = 300.0\n",
    "szn_length = 250.0\n",
    "year_length = 400.0\n",
    "Nt_szn = int(szn_length / dt_szn)\n",
    "szn_avg_window = 5.0\n",
    "burnin_time = 500.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(model_crommelin_seasonal)\n",
    "fundamental_param_dict = dict({\"b\": 0.5, \"beta\": 1.25, \"gamma_limits\": [0.15, 0.22], \"C\": 0.1, \"x1star\": 0.95, \"r\": -0.801, \"year_length\": year_length})\n",
    "crom = model_crommelin_seasonal.SeasonalCrommelinModel(fundamental_param_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create \"reanalysis\" in the file folder reserved for contiguous data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_filename_ra = join(ra_dir_contiguous,\"crom_long.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integrated through time 1000.0000000001588 out of 40499.5\n",
      "Integrated through time 2000.0999999992764 out of 40499.5\n",
      "Integrated through time 3000.099999998367 out of 40499.5\n",
      "Integrated through time 4000.0999999974574 out of 40499.5\n",
      "Integrated through time 5000.0000000006585 out of 40499.5\n",
      "Integrated through time 6000.000000004296 out of 40499.5\n",
      "Integrated through time 7000.000000007934 out of 40499.5\n",
      "Integrated through time 8000.000000011572 out of 40499.5\n",
      "Integrated through time 9000.00000001521 out of 40499.5\n",
      "Integrated through time 10000.000000018848 out of 40499.5\n",
      "Integrated through time 11000.000000022486 out of 40499.5\n",
      "Integrated through time 12000.000000026124 out of 40499.5\n",
      "Integrated through time 13000.000000029762 out of 40499.5\n",
      "Integrated through time 14000.0000000334 out of 40499.5\n",
      "Integrated through time 15000.000000037038 out of 40499.5\n",
      "Integrated through time 16000.000000040676 out of 40499.5\n",
      "Integrated through time 17000.00000003311 out of 40499.5\n",
      "Integrated through time 18000.000000018557 out of 40499.5\n",
      "Integrated through time 19000.000000004005 out of 40499.5\n",
      "Integrated through time 20000.099999989452 out of 40499.5\n",
      "Integrated through time 21000.0999999749 out of 40499.5\n",
      "Integrated through time 22000.09999996035 out of 40499.5\n",
      "Integrated through time 23000.099999945796 out of 40499.5\n",
      "Integrated through time 24000.099999931244 out of 40499.5\n",
      "Integrated through time 25000.099999916692 out of 40499.5\n",
      "Integrated through time 26000.09999990214 out of 40499.5\n",
      "Integrated through time 27000.09999988759 out of 40499.5\n",
      "Integrated through time 28000.099999873037 out of 40499.5\n",
      "Integrated through time 29000.099999858485 out of 40499.5\n",
      "Integrated through time 30000.099999843933 out of 40499.5\n",
      "Integrated through time 31000.09999982938 out of 40499.5\n",
      "Integrated through time 32000.09999981483 out of 40499.5\n",
      "Integrated through time 33000.09999980028 out of 40499.5\n",
      "Integrated through time 34000.09999978573 out of 40499.5\n",
      "Integrated through time 35000.09999977118 out of 40499.5\n",
      "Integrated through time 36000.099999756625 out of 40499.5\n",
      "Integrated through time 37000.09999974207 out of 40499.5\n",
      "Integrated through time 38000.09999972752 out of 40499.5\n",
      "Integrated through time 39000.09999971297 out of 40499.5\n",
      "Integrated through time 40000.09999969842 out of 40499.5\n"
     ]
    }
   ],
   "source": [
    "# Run the model forward\n",
    "x0 = np.zeros((1,7))\n",
    "x0[0,6] = (1957 + 0.2)*fundamental_param_dict[\"year_length\"]  # Starting time is about 20% of the way through 1957 (arbitrary)\n",
    "dt_save = 0.5\n",
    "tmax_save = 5*fundamental_param_dict[\"year_length\"] + burnin_time\n",
    "t_save = np.arange(0,tmax_save,dt_samp)\n",
    "crom.integrate_and_save(x0,t_save,traj_filename_ra,burnin_time=burnin_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(traj_filename_ra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'b': 0.5,\n",
       " 'beta': 1.25,\n",
       " 'gamma_limits': array([0.15, 0.22]),\n",
       " 'C': 0.1,\n",
       " 'x1star': 0.95,\n",
       " 'r': -0.801,\n",
       " 'year_length': 400.0,\n",
       " 'xstar': array([ 0.95   ,  0.     ,  0.     , -0.76095,  0.     ,  0.     ]),\n",
       " 'alpha': array([0.24008435, 0.73437566]),\n",
       " 'delta': array([ 0.38413496, -1.24278958]),\n",
       " 'epsilon': 1.44050610585137}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_filename_ra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create \"hindcast\" data in the file folder reserved for hindcast data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate hindcast dataset\n",
    "t_abs_range = crom.q[\"year_length\"]*np.array([1960,1970])\n",
    "crom.generate_hindcast_dataset(\n",
    "    traj_filename_ra,hc_dir,t_abs_range,dt_samp,\n",
    "    ens_size=30,ens_duration=47,ens_gap=13,pert_scale=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract features of interest from both the reanalysis and hindcast datasets. This will be expensive, as we have to read from a large database of files. Therefore, we should minimize the number of times we do this in development. Therefore, we should read in ALL possible features we MIGHT use for the downstream tasks of K-means clustering. Some extra reduction is likely necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all features of potential use from the reanalysis dataset. \n",
    "# Don't waste data by time-delaying, that's just silly\n",
    "feat_crom = feature_crommelin.SeasonalCrommelinModelFeatures(\n",
    "    szn_start,szn_length,year_length,Nt_szn,\n",
    "    szn_avg_window,dt_samp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the already-executed model (contiguous)\n",
    "X_ra_cont = xr.open_dataset(traj_filename_ra)[\"X\"]\n",
    "print(X_ra_cont.sel(feature=\"x1\").isel(t_sim=0))\n",
    "print(X_ra_cont.sel(feature=\"x2\").isel(t_sim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot x1 and x4 over time for 4 annual cycles\n",
    "fig,ax = plt.subplots(ncols=2, figsize=(12,6))\n",
    "xr.plot.plot(\n",
    "    X_ra_cont.sel(feature='x1',member=0)\n",
    "    .where(X_ra_cont['t_sim'] < 4*crom.q[\"year_length\"], drop=True),\n",
    "    x='t_sim', ax=ax[0]\n",
    ")\n",
    "xr.plot.plot(\n",
    "    X_ra_cont.sel(feature='x4',member=0)\n",
    "    .where(X_ra_cont['t_sim'] < 4*crom.q[\"year_length\"], drop=True),\n",
    "    x='t_sim', ax=ax[1]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the climatology\n",
    "feat_crom.compute_climatology(in_filename,save_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some hindcasts on top of climatology\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
